# -*- coding: utf-8 -*-
"""MOVIE GENRE CLASSIFICATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iOyGDXudMe3yfHHDn6WOJH68AMwd5KjC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
import nltk #a powerful library for working with human language data
from nltk.corpus import stopwords #for cleaning
from nltk.stem import LancasterStemmer ##for cleaning
from sklearn.metrics import classification_report, accuracy_score,confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

train_path="/content/train_data.txt"
train_data = pd.read_csv(train_path,sep=":::",names=[
    "TITLE","GENRE","DESCRIPTION"],engine="python")

train_data

train_data.info()

train_data.describe(include='object').T

train_data.isnull().sum()

train_data.GENRE.unique()

test_path="/content/test_data.txt"
test_data = pd.read_csv(test_path,sep=":::",names=[
    "TITLE","DESCRIPTION"],engine="python")
test_data.head()

test_data.info()

test_data.describe(include='object').T

test_data.duplicated().sum()

plt.figure(figsize=(10,10))
sns.countplot(data=train_data,y="GENRE",order=
              train_data["GENRE"].value_counts().index,palette="YlGnBu")
plt.show()

plt.figure(figsize=(27,7))
sns.countplot(data=train_data, x="GENRE", order=
              train_data["GENRE"].value_counts().index, palette = "YlGnBu")
plt.show()

nltk.download('stopwords')
nltk.download('punkt')

print(train_data["DESCRIPTION"].dtypes)
print(test_data["DESCRIPTION"].dtypes)

stemmer = LancasterStemmer()
stop_words = set(stopwords.words("english"))  # Stopwords set

def cleaning_data(text):
    text = text.lower()
    text = re.sub(r'@\S+', '', text)
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'.pic\S+', '', text)
    text = re.sub(r'[^a-zA-Z+]', ' ', text)  # Change to replace non-characters with a space
    text = "".join([i for i in text if i not in string.punctuation])
    words = nltk.word_tokenize(text)
    # Use the predefined stop_words variable instead of redefining it inside the function
    text = " ".join([i for i in words if i not in stop_words and len(i) > 2])
    text = re.sub(r"\s+", " ", text).strip()  # Replace multiple spaces with a single space
    return text

train_data["TextCleaning"] = train_data["DESCRIPTION"].apply(cleaning_data)
test_data["TextCleaning"] = test_data["DESCRIPTION"].apply(cleaning_data)


train_data

test_data

vectorize = TfidfVectorizer()

x_train = vectorize.fit_transform(train_data["TextCleaning"])
x_test = vectorize.fit_transform(test_data["TextCleaning"])


from imblearn.over_sampling import RandomOverSampler
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from time import time
from sklearn.metrics import *
import warnings
warnings.filterwarnings('ignore')


y_test = pd.read_csv("/content/test_data_solution.txt",sep=":::",
                       usecols=[2],header=None).rename(columns={2:'Actual_Genre'})
y_test.head()

x = x_train
y = train_data["GENRE"]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=42)

NB = MultinomialNB(alpha=0.015)
start_time = time()
NB.fit(x_train,y_train)
y_pred = NB.predict(x_test)
print('Accuracy :',accuracy_score(y_test,y_pred))
end_time = time()
print('Running Time : ',round(end_time - start_time,2),'Secounds')

model = SVC()
model.fit(x_train, y_train)
model.score(x_train, y_train)

y_pred = model.predict(x_test)
y_pred

accuracy = accuracy_score(y_test, y_pred)
print("Validation Accuracy:", accuracy)

